{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['state', 'facility_type_jail', 'facility_type_prison',\n",
      "       'how_often_discuss_politics', 'how_get_news', 'news_source',\n",
      "       'ever_voted', 'direction_country_headed',\n",
      "       'how_often_officials_acting_in_your_interest',\n",
      "       'which_party_for_cj_reform', 'stance_on_assault_weapons_ban',\n",
      "       'stance_on_marijuana_legalization',\n",
      "       'stance_on_tightening_border_security', 'stance_on_raise_min_wage',\n",
      "       'country_most_important_problem', 'race_affects_politics',\n",
      "       'explain_race_affects_politics', 'should_incarcerated_vote',\n",
      "       'incarceration_impacts_motivation_to_vote',\n",
      "       'politics_changed_since_incarcerated',\n",
      "       'explain_politics_changed_since_incarcerated',\n",
      "       'cj_important_issue_eliminating_mandatory_mins',\n",
      "       'cj_important_issue_reducing_racial_bias',\n",
      "       'cj_important_issue_abolishing_death_penalty',\n",
      "       'cj_important_issue_lowering_incarceration_rates_rural_communities',\n",
      "       'cj_important_issue_improving_prison_conds',\n",
      "       'cj_important_issue_restoring_voting_rights',\n",
      "       'cj_important_issue_reducing_prison_pop',\n",
      "       'cj_important_issue_ending_war_on_drugs',\n",
      "       'cj_important_issue_ending_private_prisons',\n",
      "       'cj_important_issue_lowering_sentences_violent_crimes',\n",
      "       'cj_important_issue_raising_wages_incarcerated_workers', 'who_vote_for',\n",
      "       'approve_disapprove_trump', 'party', 'length_in_this_facility',\n",
      "       'sentence_length', 'ethnicity', 'age', 'gender',\n",
      "       'highest_education_level', 'identifies_as_black', 'identifies_as_white',\n",
      "       'identifies_as_native', 'identifies_as_asian',\n",
      "       'identifies_as_hawaiian_or_pac_islander', 'identifies_as_other_race',\n",
      "       'identifies_as_not_sure_of_race', 'identifies_as_hispanic_or_latinx',\n",
      "       'paper', 'online'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Importing modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Read data into papers\n",
    "data = pd.read_csv(\"~/Google Drive/Research Assistant/Work With David Knight/Survey of the Incarcerated/TMPPoliticalSurveyFULL_ForDavid.csv\", encoding = \"ISO-8859-1\")\n",
    "\n",
    "# Print head\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Cleaning \n",
    "Since the goal of this analysis is to perform topic modeling, let's focus only on the text data from each paper, and drop other metadata columns. Also, for the demonstration, we'll only look at 100 papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert an id index for future work\n",
    "data[\"Survey_ID\"] = data.index + 1\n",
    "\n",
    "# Remove the columns\n",
    "str_data = data[[\"Survey_ID\", \"explain_politics_changed_since_incarcerated\",\\\n",
    "                 \"explain_race_affects_politics\", 'identifies_as_black', 'identifies_as_white',\n",
    "                 'identifies_as_native', 'identifies_as_asian', \n",
    "                 'identifies_as_hawaiian_or_pac_islander', 'identifies_as_other_race',\n",
    "                 'identifies_as_not_sure_of_race', 'identifies_as_hispanic_or_latinx']]\n",
    "# Print out the first rows of papers\n",
    "str_data.columns = [\"Survey_ID\", \"p_change\", \"r_effect\", \"black\", \"white\", \"native\", \"asian\",\n",
    "                   \"hawaiian\", \"other_race\", \"unsure_race\", \"latinx\"]\n",
    "str_data = str_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the regular expression library and the nltk word library\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "# Create a function to remove nonsense words\n",
    "words = set(nltk.corpus.words.words())\n",
    "def clean_sent(sent):\n",
    "    return \" \".join(w for w in nltk.wordpunct_tokenize(sent) \\\n",
    "     if w.lower() in words or not w.isalpha())\n",
    "\n",
    "strv_list = [\"p_change\", \"r_effect\"]\n",
    "for strv in strv_list:\n",
    "    # Remove punctuation & Convert the titles to lowercase\n",
    "    str_data[strv] = str_data[strv].map(lambda x: re.sub(r\"(?<=\\w)[^\\s\\w](,.?![^\\s\\w])\", \"\", x)).map(lambda x: x.lower())\n",
    "    # Remove nonsense words\n",
    "    str_data[strv] = str_data[strv].apply(clean_sent)\n",
    "    # Transform blank cells to NaN & Drop NaN\n",
    "    str_data = str_data.replace(r'^\\s*$', np.nan, regex=True).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Exploratory Analysis \n",
    "To verify whether the preprocessing, we’ll make a simple word cloud using the wordcloud package to get a visual representation of most common words. It is key to understanding the data and ensuring we are on the right track, and if any more preprocessing is necessary before training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the wordcloud library\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "def make_wordcloud(strv_column, name):\n",
    "    assert isinstance(name, str), \"It should be the name of the variable you observed.\"\n",
    "    \n",
    "    # Join the different processed titles together.\n",
    "    long_string = ','.join(list(strv_column.values))\n",
    "    # Create a WordCloud object\n",
    "    wordcloud = WordCloud(background_color=\"white\", max_words=100000, contour_width=3, contour_color='steelblue')\n",
    "    # Generate a word cloud\n",
    "    wordcloud.generate(long_string)\n",
    "        ## Visualize the word cloud\n",
    "        #wordcloud.to_image()\n",
    "    # Export the word cloud image\n",
    "    wordcloud.to_file(\"{}.png\".format(name))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_wordcloud(str_data[\"p_change\"], \"p_change\")\n",
    "make_wordcloud(str_data[\"r_effect\"], \"r_effect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Prepare text for LDA analysis \n",
    "Next, let’s work to transform the textual data in a format that will serve as an input for training LDA model. We start by tokenizing the text and removing stopwords. Next, we convert the tokenized object into a corpus and dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "stop_words.extend([\"don\", \"people\", \"bill\", \"step\", \"act\", \"first\", \"u\", \"n\", \"na\", \"non\", \"violent\"])\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "\n",
    "def corpus_n_id2word(dataset, strv_column):\n",
    "    str_list = dataset[strv_column].values.tolist()\n",
    "    words = list(sent_to_words(str_list))\n",
    "    # remove stop words\n",
    "    texts = remove_stopwords(words)\n",
    "    \n",
    "    # Create Dictionary\n",
    "    id2word = corpora.Dictionary(words)\n",
    "\n",
    "    # Term Document Frequency\n",
    "    corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "    return corpus, id2word,texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_corpus, pc_id2, pc_texts = corpus_n_id2word(str_data, \"p_change\")\n",
    "re_corpus, re_id2, re_texts = corpus_n_id2word(str_data, \"r_effect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: LDA model tranining and Topic Organizing\n",
    "To keep things simple, we'll keep all the parameters to default except for inputting the number of topics. For this tutorial, we will build a model with 10 topics where each topic is a combination of keywords, and each keyword contributes a certain weightage to the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# lambd for calculating relevance\n",
    "lambd = 0.6\n",
    "\n",
    "# build LDA model for the three questions\n",
    "pc_lda_model = gensim.models.LdaMulticore(corpus=pc_corpus, id2word=pc_id2, num_topics=6)\n",
    "re_lda_model7 = gensim.models.LdaMulticore(corpus=re_corpus, id2word=re_id2, num_topics=7)\n",
    "re_lda_model6 = gensim.models.LdaMulticore(corpus=re_corpus, id2word=re_id2, num_topics=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "def topic_word_table(lda_model, corpus, id2, num_topics, lambd):\n",
    "    # build LDAvis for further analysis\n",
    "    LDAvis_prepared = pyLDAvis.gensim.prepare(topic_model=lda_model, corpus=corpus, dictionary=id2)\n",
    "    # organize relevance table\n",
    "    all_topics = {}\n",
    "    lambd = lambd  # Adjust this accordingly\n",
    "    for i in range(1, num_topics+1): #Adjust number of topics in final model\n",
    "        topic = LDAvis_prepared.topic_info[LDAvis_prepared.topic_info.Category == 'Topic'+str(i)]\n",
    "        topic['relevance'] = topic['loglift']*(1-lambd)+topic['logprob']*lambd\n",
    "        all_topics['Topic '+str(i)] = topic.sort_values(by='relevance', ascending=False).Term[:10].values\n",
    "        \n",
    "    # dict to dataframe\n",
    "    newtable = pd.DataFrame.from_dict(all_topics, orient='index')\n",
    "    \n",
    "    return newtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Q political change\n",
    "pc_table = topic_word_table(pc_lda_model, pc_corpus, pc_id2, 6, lambd)\n",
    "#print(pc_table)\n",
    "    # export csv\n",
    "pc_table.to_csv(\"pc_twt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Q racial effect - 7 topics\n",
    "pc_table = topic_word_table(re_lda_model7, re_corpus, re_id2, 7, lambd)\n",
    "#print(pc_table)\n",
    "    # export csv\n",
    "pc_table.to_csv(\"re7_twt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Q racial effect - 6 topics\n",
    "pc_table = topic_word_table(re_lda_model6, re_corpus, re_id2, 6, lambd)\n",
    "#print(pc_table)\n",
    "    # export csv\n",
    "pc_table.to_csv(\"re6_twt.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Finding the Dominat Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    \n",
    "    # Format\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1).reset_index()\n",
    "    sent_topics_df.columns = [\"Survey_ID\", \"Dominant_Topic\", \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "    \n",
    "    return sent_topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Survey_ID  Dominant_Topic  Topic_Perc_Contrib  \\\n",
      "0             0             0.0              0.1667   \n",
      "1             1             2.0              0.9619   \n",
      "2             2             3.0              0.7205   \n",
      "3             3             0.0              0.5806   \n",
      "4             4             0.0              0.5008   \n",
      "...         ...             ...                 ...   \n",
      "3299       3299             0.0              0.1667   \n",
      "3300       3300             0.0              0.1667   \n",
      "3301       3301             3.0              0.9148   \n",
      "3302       3302             2.0              0.8312   \n",
      "3303       3303             0.0              0.1667   \n",
      "\n",
      "                                               Keywords  \\\n",
      "0     prison, politics, care, yes, political, system...   \n",
      "1     political, never, get, politics, yes, prison, ...   \n",
      "2     yes, never, country, better, see, time, system...   \n",
      "3     prison, politics, care, yes, political, system...   \n",
      "4     prison, politics, care, yes, political, system...   \n",
      "...                                                 ...   \n",
      "3299  prison, politics, care, yes, political, system...   \n",
      "3300  prison, politics, care, yes, political, system...   \n",
      "3301  yes, never, country, better, see, time, system...   \n",
      "3302  political, never, get, politics, yes, prison, ...   \n",
      "3303  prison, politics, care, yes, political, system...   \n",
      "\n",
      "                                                   Text  \n",
      "0                                                    []  \n",
      "1     [feel, parole, board, chance, chance, keep, co...  \n",
      "2                                            [yes, bit]  \n",
      "3                                                [full]  \n",
      "4     [never, considered, prison, population, prison...  \n",
      "...                                                 ...  \n",
      "3299                                                 []  \n",
      "3300                                                 []  \n",
      "3301  [yes, mass, incarceration, sent, prison, every...  \n",
      "3302            [yes, president, political, completely]  \n",
      "3303                                                 []  \n",
      "\n",
      "[3304 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Q political change\n",
    "pc_topic_sents_keywords = format_topics_sentences(ldamodel=pc_lda_model, corpus=pc_corpus, texts=pc_texts)\n",
    "print(pc_topic_sents_keywords)\n",
    "# stat aggregate\n",
    "topic_stat = pc_topic_sents_keywords[[\"Dominant_Topic\",\n",
    "                                      \"Topic_Perc_Contrib\"]].groupby(\"Dominant_Topic\").agg([\"count\", \"mean\"])\n",
    "# to csv\n",
    "topic_stat.to_csv(\"pc_topic_contri.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q racial effect - 7 topics\n",
    "re_topic_sents_keywords = format_topics_sentences(ldamodel=re_lda_model7, corpus=re_corpus, texts=re_texts)\n",
    "# stat aggregate\n",
    "topic_stat2 = re_topic_sents_keywords[[\"Dominant_Topic\", \n",
    "                                       \"Topic_Perc_Contrib\"]].groupby(\"Dominant_Topic\").agg([\"count\", \"mean\"])\n",
    "# to csv\n",
    "topic_stat2.to_csv(\"re7_topic_contri.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q racial effect - 6 topics\n",
    "re_topic_sents_keywords = format_topics_sentences(ldamodel=re_lda_model6, corpus=re_corpus, texts=re_texts)\n",
    "# stat aggregate\n",
    "topic_stat3 = re_topic_sents_keywords[[\"Dominant_Topic\", \n",
    "                                       \"Topic_Perc_Contrib\"]].groupby(\"Dominant_Topic\").agg([\"count\", \"mean\"])\n",
    "# to csv\n",
    "topic_stat3.to_csv(\"re6_topic_contri.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_topic = str_data.merge(re_topic_sents_keywords, on=\"Survey_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey_ID</th>\n",
       "      <th>p_change</th>\n",
       "      <th>r_effect</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>native</th>\n",
       "      <th>asian</th>\n",
       "      <th>hawaiian</th>\n",
       "      <th>other_race</th>\n",
       "      <th>unsure_race</th>\n",
       "      <th>latinx</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[No]</td>\n",
       "      <td>[Not at all] I'm not racist, all of the human ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5828</td>\n",
       "      <td>race, sure, prison, black, white, racist, know...</td>\n",
       "      <td>[sure]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>I feel that the parole board gives the some of...</td>\n",
       "      <td>I'm not sure about that</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8318</td>\n",
       "      <td>race, deal, racial, prison, great, political, ...</td>\n",
       "      <td>[understand, question, maybe, typo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Yes alittle bit</td>\n",
       "      <td>I am not really sure about that one</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7466</td>\n",
       "      <td>dont, white, race, racial, prison, like, see, ...</td>\n",
       "      <td>[try, vote, based, many, vote, white]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Most politicians are full of shit.</td>\n",
       "      <td>I do not understand this question, maybe there...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7207</td>\n",
       "      <td>dont, white, race, racial, prison, like, see, ...</td>\n",
       "      <td>[dont, know]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>I never considered the prison population or pr...</td>\n",
       "      <td>I try to vote based on the issues but I am whi...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8798</td>\n",
       "      <td>dont, white, race, racial, prison, like, see, ...</td>\n",
       "      <td>[racism, still, big, problem, today, outside]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survey_ID                                           p_change  \\\n",
       "0          1                                               [No]   \n",
       "1          3  I feel that the parole board gives the some of...   \n",
       "2          4                                    Yes alittle bit   \n",
       "3          6                 Most politicians are full of shit.   \n",
       "4          7  I never considered the prison population or pr...   \n",
       "\n",
       "                                            r_effect  black  white  native  \\\n",
       "0  [Not at all] I'm not racist, all of the human ...  False   True   False   \n",
       "1                            I'm not sure about that  False   True   False   \n",
       "2                I am not really sure about that one  False   True   False   \n",
       "3  I do not understand this question, maybe there...   True  False   False   \n",
       "4  I try to vote based on the issues but I am whi...  False   True   False   \n",
       "\n",
       "   asian  hawaiian  other_race  unsure_race  latinx  Dominant_Topic  \\\n",
       "0  False     False       False        False   False             2.0   \n",
       "1  False     False       False        False   False             1.0   \n",
       "2  False     False       False        False   False             3.0   \n",
       "3  False     False       False        False   False             3.0   \n",
       "4  False     False       False        False   False             3.0   \n",
       "\n",
       "   Topic_Perc_Contrib                                           Keywords  \\\n",
       "0              0.5828  race, sure, prison, black, white, racist, know...   \n",
       "1              0.8318  race, deal, racial, prison, great, political, ...   \n",
       "2              0.7466  dont, white, race, racial, prison, like, see, ...   \n",
       "3              0.7207  dont, white, race, racial, prison, like, see, ...   \n",
       "4              0.8798  dont, white, race, racial, prison, like, see, ...   \n",
       "\n",
       "                                            Text  \n",
       "0                                         [sure]  \n",
       "1            [understand, question, maybe, typo]  \n",
       "2          [try, vote, based, many, vote, white]  \n",
       "3                                   [dont, know]  \n",
       "4  [racism, still, big, problem, today, outside]  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_topic = str_data.merge(pc_topic_sents_keywords, on=\"Survey_ID\")\n",
    "f = pc_topic[pc_topic[\"other_race\"]==True]\n",
    "a = f[[\"Dominant_Topic\", \"Topic_Perc_Contrib\"]].groupby(\"Dominant_Topic\").agg([\"count\", \"mean\"])\n",
    "a.columns = a.columns.droplevel()\n",
    "a[\"x\"] = round(a[\"count\"]/f.shape[0], 5)\n",
    "a.to_csv(\"b.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 15)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_topic[pc_topic[\"hawaiian\"]==True].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Topic Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "\n",
    "# Get topic weights\n",
    "topic_weights = []\n",
    "for i, row_list in enumerate(group_lda_model[group_corpus]):\n",
    "    topic_weights.append([w for i, w in row_list[0]])\n",
    "\n",
    "# Array of topic weights    \n",
    "arr = pd.DataFrame(topic_weights).fillna(0).values\n",
    "\n",
    "# Keep the well separated points (optional)\n",
    "arr = arr[np.amax(arr, axis=1) > 0.35]\n",
    "\n",
    "# Dominant topic number in each doc\n",
    "topic_num = np.argmax(arr, axis=1)\n",
    "\n",
    "# tSNE Dimension Reduction\n",
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "tsne_lda = tsne_model.fit_transform(arr)\n",
    "\n",
    "# Plot the Topic Clusters using Bokeh\n",
    "output_notebook()\n",
    "n_topics = 4\n",
    "mycolors = np.array([color for name, color in mcolors.TABLEAU_COLORS.items()])\n",
    "plot = figure(title=\"t-SNE Clustering of {} LDA Topics\".format(n_topics), \n",
    "              plot_width=900, plot_height=700)\n",
    "plot.scatter(x=tsne_lda[:,0], y=tsne_lda[:,1], color=mycolors[topic_num])\n",
    "show(plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Visualizing Topic Interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(group_lda_model, group_corpus, dictionary=group_lda_model.id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyLDAvis.save_html(vis, 'group_lda.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "geo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
